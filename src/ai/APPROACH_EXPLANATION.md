# ğŸ” Approche UtilisÃ©e : LangChain Tools (Ni RAG, Ni MCP)

## ğŸ“Š RÃ©sumÃ©

**Approche utilisÃ©e :** **LangChain Tools** (Outils LangChain)

**âŒ Non utilisÃ© :** RAG (Retrieval Augmented Generation)  
**âŒ Non utilisÃ© :** MCP (Model Context Protocol)

---

## âœ… Ce qui est utilisÃ© : LangChain Tools

### Qu'est-ce que LangChain Tools ?

Les **LangChain Tools** sont des fonctions que l'agent IA peut appeler pour interagir avec des systÃ¨mes externes (base de donnÃ©es, APIs, services). C'est une approche de **function calling** oÃ¹ l'agent dÃ©cide dynamiquement quels outils utiliser en fonction de la question de l'utilisateur.

### Comment Ã§a fonctionne dans notre implÃ©mentation ?

```
1. Utilisateur pose une question
   â†“
2. LangChain Agent analyse la question
   â†“
3. Agent sÃ©lectionne l'outil appropriÃ© (ex: search_customers)
   â†“
4. L'outil est exÃ©cutÃ© â†’ Appelle un service NestJS
   â†“
5. Le service interroge la base de donnÃ©es
   â†“
6. Les donnÃ©es sont formatÃ©es et retournÃ©es Ã  l'agent
   â†“
7. L'agent formate la rÃ©ponse finale pour l'utilisateur
```

### Code dans notre implÃ©mentation

```typescript
// src/ai/tools/grappe-tools.ts
import { tool } from 'langchain';

export function createGrappeTools(
  customerService: CustomerService,
  // ... autres services
  tenantId: string,
) {
  return [
    // Outil LangChain
    tool(
      async ({ customerId }: { customerId: string }) => {
        // Appel direct au service NestJS
        const customer = await customerService.findOne(customerId);
        // Formatage et retour
        return formatResponseAsJson(customer);
      },
      {
        name: 'search_customers',
        description: 'Rechercher des clients...',
        schema: { /* schÃ©ma JSON pour l'agent */ },
      },
    ),
  ];
}
```

```typescript
// src/ai/ai.service.ts
const tools = createGrappeTools(/* services */, tenantId);

// CrÃ©ation de l'agent avec les outils
const agent = createAgent({
  model,
  tools,  // â† Les outils LangChain
  systemPrompt: SYSTEM_PROMPT,
});
```

---

## âŒ Pourquoi pas RAG ?

### Qu'est-ce que RAG ?

**RAG (Retrieval Augmented Generation)** est une approche qui :
1. CrÃ©e des embeddings (vecteurs) des documents
2. Stocke ces embeddings dans une base de donnÃ©es vectorielle
3. Lors d'une question, recherche les documents similaires
4. Injecte ces documents dans le contexte du LLM
5. Le LLM gÃ©nÃ¨re une rÃ©ponse basÃ©e sur ces documents

### Pourquoi on ne l'utilise pas ?

âŒ **Pas de base de donnÃ©es vectorielle** : On n'utilise pas de base comme Pinecone, Weaviate, ou Chroma  
âŒ **Pas d'embeddings** : On ne crÃ©e pas de vecteurs des donnÃ©es  
âŒ **Pas de recherche sÃ©mantique** : On ne fait pas de recherche par similaritÃ©  
âŒ **AccÃ¨s direct aux donnÃ©es** : On interroge directement la base de donnÃ©es PostgreSQL via les services NestJS

### Quand utiliser RAG ?

RAG serait utile si :
- Vous avez beaucoup de documents non structurÃ©s (PDFs, textes longs)
- Vous voulez rechercher par similaritÃ© sÃ©mantique
- Vous avez besoin de contexte historique ou de documentation
- Les donnÃ©es changent frÃ©quemment et vous voulez Ã©viter de rÃ©entraÃ®ner le modÃ¨le

### Notre cas d'usage

âœ… **DonnÃ©es structurÃ©es** : Clients, devis, commandes sont dans une base de donnÃ©es structurÃ©e  
âœ… **RequÃªtes prÃ©cises** : On veut des donnÃ©es exactes, pas des similaritÃ©s  
âœ… **AccÃ¨s direct** : Les services NestJS fournissent dÃ©jÃ  des mÃ©thodes de recherche prÃ©cises  
âœ… **Temps rÃ©el** : Les donnÃ©es sont toujours Ã  jour, pas besoin de les indexer

---

## âŒ Pourquoi pas MCP ?

### Qu'est-ce que MCP ?

**MCP (Model Context Protocol)** est un protocole dÃ©veloppÃ© par Anthropic pour standardiser la communication entre les LLMs et les outils externes. C'est une spÃ©cification pour crÃ©er des serveurs d'outils que les LLMs peuvent appeler.

### Pourquoi on ne l'utilise pas ?

âŒ **Pas de serveur MCP** : On n'a pas de serveur MCP qui expose les outils  
âŒ **LangChain natif** : On utilise directement les outils LangChain, pas le protocole MCP  
âŒ **Pas de standardisation MCP** : Les outils sont dÃ©finis directement dans LangChain

### Quand utiliser MCP ?

MCP serait utile si :
- Vous voulez standardiser l'accÃ¨s aux outils
- Vous avez plusieurs applications qui doivent partager les mÃªmes outils
- Vous voulez une architecture plus dÃ©couplÃ©e
- Vous utilisez des modÃ¨les Anthropic (Claude) qui supportent nativement MCP

### Notre cas d'usage

âœ… **LangChain suffit** : Les outils LangChain sont parfaitement adaptÃ©s Ã  nos besoins  
âœ… **IntÃ©gration directe** : Pas besoin d'une couche de protocole supplÃ©mentaire  
âœ… **Google Gemini** : On utilise Google Gemini qui fonctionne bien avec LangChain Tools

---

## ğŸ“Š Comparaison des approches

| CaractÃ©ristique | LangChain Tools (Notre approche) | RAG | MCP |
|----------------|----------------------------------|-----|-----|
| **Type de donnÃ©es** | StructurÃ©es (BDD) | Non structurÃ©es (documents) | StructurÃ©es ou non |
| **Recherche** | PrÃ©cise (requÃªtes SQL) | SÃ©mantique (similaritÃ©) | DÃ©pend de l'implÃ©mentation |
| **Base vectorielle** | âŒ Non | âœ… Oui | âŒ Non (mais possible) |
| **Temps rÃ©el** | âœ… Oui | âš ï¸ DÃ©pend de l'indexation | âœ… Oui |
| **ComplexitÃ©** | Faible | Moyenne Ã  Ã©levÃ©e | Moyenne |
| **Performance** | Rapide (requÃªtes directes) | Plus lent (recherche + gÃ©nÃ©ration) | Rapide |
| **Mise Ã  jour** | ImmÃ©diate | NÃ©cessite rÃ©indexation | ImmÃ©diate |

---

## ğŸ¯ Avantages de notre approche (LangChain Tools)

### âœ… SimplicitÃ©
- Pas besoin de base vectorielle
- Pas besoin d'embeddings
- IntÃ©gration directe avec les services existants

### âœ… Performance
- RequÃªtes directes Ã  la base de donnÃ©es
- Pas de recherche vectorielle coÃ»teuse
- RÃ©ponses rapides

### âœ… PrÃ©cision
- DonnÃ©es exactes, pas de similaritÃ© approximative
- Filtrage multi-tenant garanti
- Validation des donnÃ©es via les services NestJS

### âœ… Maintenance
- Code simple et comprÃ©hensible
- Facile Ã  dÃ©boguer
- Facile Ã  Ã©tendre avec de nouveaux outils

### âœ… Temps rÃ©el
- DonnÃ©es toujours Ã  jour
- Pas de dÃ©lai d'indexation
- Synchronisation automatique

---

## ğŸ”„ Comment migrer vers RAG (si nÃ©cessaire)

Si vous voulez ajouter RAG pour des cas d'usage spÃ©cifiques :

1. **Installer les dÃ©pendances** :
```bash
npm install @langchain/openai @langchain/community
npm install chromadb # ou pinecone, weaviate, etc.
```

2. **CrÃ©er un outil RAG** :
```typescript
import { Chroma } from '@langchain/community/vectorstores/chroma';
import { OpenAIEmbeddings } from '@langchain/openai/embeddings';

const vectorStore = new Chroma(/* config */);

tool(
  async ({ query }: { query: string }) => {
    const results = await vectorStore.similaritySearch(query, 5);
    return formatResponseAsJson(results);
  },
  {
    name: 'search_documents',
    description: 'Rechercher dans les documents par similaritÃ© sÃ©mantique',
  },
),
```

3. **Ajouter l'outil Ã  createGrappeTools()**

---

## ğŸ”„ Comment migrer vers MCP (si nÃ©cessaire)

Si vous voulez utiliser MCP :

1. **CrÃ©er un serveur MCP** qui expose vos outils
2. **Utiliser un client MCP** dans LangChain
3. **Adapter les outils** pour suivre le protocole MCP

Cependant, pour notre cas d'usage, **LangChain Tools est la meilleure solution**.

---

## ğŸ“š RÃ©fÃ©rences

- [LangChain Tools Documentation](https://js.langchain.com/docs/modules/tools/)
- [RAG Documentation](https://js.langchain.com/docs/use_cases/question_answering/)
- [MCP Specification](https://modelcontextprotocol.io/)

---

## âœ… Conclusion

**Notre implÃ©mentation utilise LangChain Tools**, qui est :
- âœ… Parfait pour les donnÃ©es structurÃ©es
- âœ… Simple Ã  maintenir
- âœ… Performant
- âœ… PrÃ©cis
- âœ… AdaptÃ© Ã  notre architecture NestJS

**RAG et MCP ne sont pas nÃ©cessaires** pour notre cas d'usage actuel, mais peuvent Ãªtre ajoutÃ©s si besoin Ã  l'avenir.

---

*DerniÃ¨re mise Ã  jour : 2024*

